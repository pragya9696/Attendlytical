{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18714cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "575733d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a single face from a given photograph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mtcnn\n",
    "from PIL import Image\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "    # load image from file\n",
    "    pixels = plt.imread(filename)\n",
    "    # create the detector, using default weights\n",
    "    detector = mtcnn.MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    # extract the bounding box from the first face\n",
    "    faces=[]\n",
    "    for x in range(len(results)):\n",
    "        x1, y1, width, height = results[x]['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = np.asarray(image)\n",
    "        faces.append(face_array)\n",
    "    return(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f8aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "def detect(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.imwrite(\"im.jpg\",frame[y:y+h+5,x:x+w+5])\n",
    "        c= \"outsider\"\n",
    "        try:\n",
    "            for person in os.listdir(\"class\"):\n",
    "                obj = DeepFace.verify(\"im.jpg\", \"class/\"+person, model_name = 'ArcFace')\n",
    "                if obj[\"verified\"]:\n",
    "                    c= person\n",
    "                    break\n",
    "        except:\n",
    "            pass\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 3, 3)\n",
    "        if len(eyes)==0:\n",
    "            p= \"not attentive\"\n",
    "            cv2.putText(frame,c+\"/ Not attentive\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,1,(255, 255, 0),2)\n",
    "        else:\n",
    "            p=\"attentive\"\n",
    "            cv2.putText(frame,c+\" /Attentive\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,1,(100, 255, 0),2)\n",
    "        f = open(\"master/\"+c+\".txt\", \"a\")\n",
    "        f.write(\"\\n\"+p+\"\\t\"+str(datetime.now()))\n",
    "        f.close()\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    \n",
    "    #import time\n",
    "    #time.sleep(3.0)\n",
    "    _, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    canvas = detect(gray, frame)\n",
    "    cv2.imshow('Video', canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "def detect(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.imwrite(\"im.jpg\",frame[y:y+h+10,x:x+w+10])\n",
    "        c= \"outsider\"\n",
    "        try:\n",
    "            for person in os.listdir(\"class\"):\n",
    "                obj = DeepFace.verify(\"im.jpg\", \"class/\"+person, model_name = 'ArcFace')\n",
    "                if obj[\"verified\"]:\n",
    "                    c= person\n",
    "                    break\n",
    "        except:\n",
    "            pass\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        #roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.3, 5)\n",
    "        if len(eyes)==0:\n",
    "            p= \"not attentive\"\n",
    "            cv2.putText(frame,c+\"/ Not Attentive\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,1,(255, 255, 0),2)\n",
    "        else:\n",
    "            p=\"attentive\"\n",
    "            cv2.putText(frame,c+\" /Attentive\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,1,(100, 255, 0),2)\n",
    "        f = open(\"master/\"+c+\".txt\", \"a\")\n",
    "        f.write(\"\\n\"+p+\" \"+str(datetime.now()))\n",
    "        f.close()\n",
    "        #for (ex, ey, ew, eh) in eyes:\n",
    "            #cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "#import time\n",
    "#time.sleep(3.0)\n",
    "frame = cv2.imread(\"WIN_20220507_20_42_43_Pro.jpg\",1)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "canvas = detect(gray, frame)\n",
    "cv2.imwrite('result.jpg', canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c664c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15607e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
